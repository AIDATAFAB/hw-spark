{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./.venv/lib/python3.12/site-packages (3.5.4)\n",
      "Requirement already satisfied: delta-spark in ./.venv/lib/python3.12/site-packages (3.3.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (75.8.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.venv/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in ./.venv/lib/python3.12/site-packages (from delta-spark) (8.6.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata>=1.0.0->delta-spark) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark delta-spark pandas setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/03 19:34:44 WARN Utils: Your hostname, codespaces-f6f13d resolves to a loopback address: 127.0.0.1; using 10.0.1.201 instead (on interface eth0)\n",
      "25/02/03 19:34:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/workspaces/hse-hw-2025-1/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/codespace/.ivy2/cache\n",
      "The jars for the packages stored in: /home/codespace/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2156aa21-d8eb-4898-9be2-b1426965ea2b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.3.0 in central\n",
      "\tfound io.delta#delta-storage;3.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 221ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2156aa21-d8eb-4898-9be2-b1426965ea2b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/6ms)\n",
      "25/02/03 19:34:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"aig\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "ss = configure_spark_with_delta_pip(builder).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/03 19:34:56 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/02/03 19:34:56 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "ss.sql(\"SELECT 1 AS x\").write.format(\"delta\").mode(\"overwrite\").saveAsTable('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "      <th>engineInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2025-02-03 19:35:07.766</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-02-03 19:32:28.318</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2025-02-03 19:31:48.126</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-02-03 19:27:51.154</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-02-03 19:26:08.526</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-02-03 19:25:53.266</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-03 19:24:23.770</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-03 19:22:34.862</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-03 19:20:30.402</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE TABLE AS SELECT</td>\n",
       "      <td>{'partitionBy': '[]', 'description': None, 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serializable</td>\n",
       "      <td>True</td>\n",
       "      <td>{'numOutputRows': '1', 'numOutputBytes': '449'...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apache-Spark/3.5.4 Delta-Lake/3.3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName  \\\n",
       "0        8 2025-02-03 19:35:07.766   None     None   \n",
       "1        7 2025-02-03 19:32:28.318   None     None   \n",
       "2        6 2025-02-03 19:31:48.126   None     None   \n",
       "3        5 2025-02-03 19:27:51.154   None     None   \n",
       "4        4 2025-02-03 19:26:08.526   None     None   \n",
       "5        3 2025-02-03 19:25:53.266   None     None   \n",
       "6        2 2025-02-03 19:24:23.770   None     None   \n",
       "7        1 2025-02-03 19:22:34.862   None     None   \n",
       "8        0 2025-02-03 19:20:30.402   None     None   \n",
       "\n",
       "                           operation  \\\n",
       "0  CREATE OR REPLACE TABLE AS SELECT   \n",
       "1  CREATE OR REPLACE TABLE AS SELECT   \n",
       "2  CREATE OR REPLACE TABLE AS SELECT   \n",
       "3  CREATE OR REPLACE TABLE AS SELECT   \n",
       "4  CREATE OR REPLACE TABLE AS SELECT   \n",
       "5  CREATE OR REPLACE TABLE AS SELECT   \n",
       "6  CREATE OR REPLACE TABLE AS SELECT   \n",
       "7  CREATE OR REPLACE TABLE AS SELECT   \n",
       "8             CREATE TABLE AS SELECT   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "1  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "2  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "3  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "4  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "5  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "6  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "7  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "8  {'partitionBy': '[]', 'description': None, 'pr...  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          7.0   Serializable          False   \n",
       "1          6.0   Serializable          False   \n",
       "2          5.0   Serializable          False   \n",
       "3          4.0   Serializable          False   \n",
       "4          3.0   Serializable          False   \n",
       "5          2.0   Serializable          False   \n",
       "6          1.0   Serializable          False   \n",
       "7          0.0   Serializable          False   \n",
       "8          NaN   Serializable           True   \n",
       "\n",
       "                                    operationMetrics userMetadata  \\\n",
       "0  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "1  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "2  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "3  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "4  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "5  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "6  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "7  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "8  {'numOutputRows': '1', 'numOutputBytes': '449'...         None   \n",
       "\n",
       "                            engineInfo  \n",
       "0  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "1  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "2  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "3  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "4  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "5  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "6  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "7  Apache-Spark/3.5.4 Delta-Lake/3.3.0  \n",
       "8  Apache-Spark/3.5.4 Delta-Lake/3.3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ss.sql(\"DESCRIBE HISTORY test\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/03 19:38:37 WARN OptimisticTransaction: Change in the table id detected in txn. Table id for txn on table at file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster was 2cb5688e-ed73-467e-9e21-84c350077631 when the txn was created and is now changed to e8c64d0f-e3fe-4440-bd19-2a337aaa0814.\n",
      "25/02/03 19:38:37 WARN DeltaLog: Change in the table id detected while updating snapshot. \n",
      "Previous snapshot = Snapshot(path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log, version=1, metadata=Metadata(2cb5688e-ed73-467e-9e21-84c350077631,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"x\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},ArrayBuffer(),Map(),Some(1738611481681)), logSegment=LogSegment(file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log,1,List(DeprecatedRawLocalFileStatus{path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log/00000000000000000000.json; isDirectory=false; length=1051; replication=1; blocksize=33554432; modification_time=1738611478766; access_time=1738611478754; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}, DeprecatedRawLocalFileStatus{path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log/00000000000000000001.json; isDirectory=false; length=1224; replication=1; blocksize=33554432; modification_time=1738611486874; access_time=1738611486862; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}),org.apache.spark.sql.delta.EmptyCheckpointProvider$@6833b7d1,1738611486874), checksumOpt=Some(VersionChecksum(Some(4ba218ca-e574-4a74-aedc-bc0d8137a7d0),449,1,None,None,1,1,None,Some(Stream()),Some(Stream()),Metadata(2cb5688e-ed73-467e-9e21-84c350077631,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"x\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},ArrayBuffer(),Map(),Some(1738611481681)),Protocol(1,2),None,None,Some(Stream(AddFile(part-00000-9aae2e4a-96a2-4739-b6c0-8a3fba71a64e-c000.snappy.parquet,Map(),449,1738611482698,false,{\"numRecords\":1,\"minValues\":{\"x\":1},\"maxValues\":{\"x\":1},\"nullCount\":{\"x\":0}},null,null,None,None,None))))))\n",
      "New snapshot = Snapshot(path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log, version=2, metadata=Metadata(e8c64d0f-e3fe-4440-bd19-2a337aaa0814,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"x\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},ArrayBuffer(),Map(),Some(1738611512154)), logSegment=LogSegment(file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log,2,List(DeprecatedRawLocalFileStatus{path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log/00000000000000000000.json; isDirectory=false; length=1051; replication=1; blocksize=33554432; modification_time=1738611478766; access_time=1738611478754; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}, DeprecatedRawLocalFileStatus{path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log/00000000000000000001.json; isDirectory=false; length=1224; replication=1; blocksize=33554432; modification_time=1738611486874; access_time=1738611486862; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}, DeprecatedRawLocalFileStatus{path=file:/workspaces/hse-hw-2025-1/spark-warehouse/test_cluster/_delta_log/00000000000000000002.json; isDirectory=false; length=1514; replication=1; blocksize=33554432; modification_time=1738611517110; access_time=1738611517102; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}),org.apache.spark.sql.delta.EmptyCheckpointProvider$@6833b7d1,1738611517110), checksumOpt=Some(VersionChecksum(Some(a077ee97-dd7a-4705-86ed-b70d741a2258),449,1,None,None,1,1,None,Some(Stream()),Some(Stream(DomainMetadata(delta.clustering,{\"clusteringColumns\":[[\"x\"]],\"domainName\":\"delta.clustering\"},false))),Metadata(e8c64d0f-e3fe-4440-bd19-2a337aaa0814,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"x\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},ArrayBuffer(),Map(),Some(1738611512154)),Protocol(1,7,None,[appendOnly,clustering,domainMetadata,invariants]),None,None,Some(Stream(AddFile(part-00000-dbe0760e-5f03-42f4-ba9c-c71b5d30d0f7-c000.snappy.parquet,Map(),449,1738611513014,false,{\"numRecords\":1,\"minValues\":{\"x\":1},\"maxValues\":{\"x\":1},\"nullCount\":{\"x\":0}},null,null,None,None,None)))))).\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE test_cluster \n",
    "USING delta CLUSTER BY (x)\n",
    "AS SELECT * FROM test\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x\n",
       "0  1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.sql(\"SELECT * FROM test_cluster WHERE x = '1'\").toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
